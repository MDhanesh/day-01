# day-01

			HTTP/1.1   Vs  HTTP/2

HTTP (HYPERTEXT TRANSFER PROTOCOL):
		Hypertext Transfer Protocol (HTTP) is an application layer protocol for transmitting hypermedia documents, such as HTML. It was designed for communication between web browsers and web servers, but it can also be used for other purposes. It was developed by Tim Berners-Lee in 1989.There are few version of HTTP such as HTTP/0.9,HTTP/1.0,HTTP/1.1 and HTTP/2.
		GET and POST is the similar method ensuring that the requests and responses traveling between the server and client in both protocols reach their destinations as traditionally formatted messages with headers and bodies.

HTTP/1.1:
		   HTTP is a top-level application protocol that exchanges information between a client computer and remote web server. HTTP\1.1 was came into use in 1997. Before that there was version called HTTP/1.0.
			In HTTP/1.0, the client had to break and remake the TCP connection with every new request, it take more time and resources. HTTP/1.1 takes care of this problem by introducing persistent connections and pipelining. With persistent connections, HTTP/1.1 assumes that a TCP connection should be kept open unless directly told to close. This allows the client to send multiple requests along the same connection without waiting for a response to each, this   improves the performance of HTTP/1.1 over HTTP/1.0.
                        HTTP/1.1 transfers the information   in plain-text messages. The first response that a client receives on an HTTP GET request is often not the fully rendered page. Instead, it contains links to additional resources needed by the requested page. The client discovers that the full rendering of the page requires these additional resources from the server only after it downloads the page. Because of this, the client will have to make additional requests to retrieve these resources. This makes more time to load the page.
PROBLEMS in HTTP/1.1:
	       Multiple data packets cannot pass each other when traveling to the same destination, there are situations in which a request at the head of the queue that cannot retrieve its required resource will block all the requests behind it. This is known as head-of-line (HOL) blocking, and is a significant problem with optimizing connection efficiency in HTTP/1.1. Adding separate, parallel TCP connections could control this issue, but there are limits to the number of concurrent TCP connections possible between a client and server, and each new connection requires significant resources.
                HTTP/1.1, flow control relies on the underlying TCP connection.  When this connection initiates, both client and server establish their buffer sizes using their system default settings. If the receiverâ€™s buffer is partially filled with data, it will tell the sender it receive window. This receive window is advertised in a signal known as an ACK packet, which is the data packet that the receiver sends to acknowledge that it received the opening signal. If this advertised receive window size is zero, the sender will send no more data until the client clears its internal buffer and then requests to resume data transmission.  using  receive windows based on the underlying TCP connection can only implement flow control on either end of the connection. Because HTTP/1.1 relies on the transport layer to avoid buffer overflow, each new TCP connection requires a separate flow control mechanism.

HTTP/2:
		HTTP/2 was came in to the publication in May 2015. HTTP/2 began as the SPDY protocol, developed primarily at Google with the intention of reducing web page load latency by using techniques such as compression, multiplexing, and prioritization. The template for the HTTP/2 has  standardization by the IETF(Internet Engineering Task Force) .
            HTTP/2 has a feature called binary framing layer, it make the HTTP/2 more significant from the HTTP/1.1. HTTP/1.1, which keeps all requests and responses in plain text format, HTTP/2 uses the binary framing layer to encapsulate all messages in binary format, while still maintaining HTTP semantics, such as verbs, methods, and headers. An application level API would still create messages in the conventional HTTP formats, but the underlying layer would then convert these messages into binary. This ensures that web applications created before HTTP/2 can continue functioning as normal when interacting with the new protocol.
	 HTTP/2 uses a more advanced compression method called HPACK that eliminates redundant information in HTTP header packets. This eliminates a few bytes from every HTTP packet.
ADVANTAGES of HTTP/2:
  In HTTP/2, the binary framing layer encodes requests/responses and cuts them up into smaller packets of information, greatly increasing the flexibility of data transfer. To lessen the effect of HOL blocking HTTP/1.1 makes a multiple TCP connections, but HTTP/2 establishes a single connection object between the two machines. Within this connection there are multiple streams of data. Each stream consists of multiple messages in the familiar request/response format. Finally, each of these messages split into smaller units called frame.
      The communication channel consists of a bunch of binary-encoded frames, each tagged to a particular stream. The identifying tags allow the connection to interleave these frames during transfer and reassemble them at the other end. The interleaved requests and responses can run in parallel without blocking the messages behind them, a process called multiplexing. Multiplexing resolves the head-of-line blocking issue in HTTP/1.1 by ensuring that no message has to wait for another to finish. This also means that servers and clients can send concurrent requests and responses, allowing for greater control and more efficient connection management



